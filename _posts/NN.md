---
published: true
---

---  
layout: post
title:  الخوارزميات المغلقة  
---  

الذكاء الاصطناعي وجد ليبقى. إذا تم استخدامه جيدًا ، يمكن أن يساعد في تحسين حياتنا وحل بعض أصعب المشكلات في العالم.  حيث يمكّن البشر والآلات من العمل بشكل تعاوني ، مع القدرة على تعزيز قدرات البشر والتكنولوجيا بما يتجاوز خيالاتنا. بالنسبة للمؤسسات والشركات يمكن أن يعني هذا زيادة في الإنتاجية وتقليل التكاليف وتحسين سرعة الوصول إلى السوق وتحسين العلاقات مع العملاء ، انعكس هذا في استطلاع [Forbes Insights](https://www.forbes.com/sites/insights-intelai/2018/07/17/on-your-marks-business-leaders-prepare-for-arms-race-in-artificial-intelligence/?sh=1224b4181946) بعنوان " قادة الأعمال يستعدون لسباق التسلح في الذكاء الاصطناعي" ، والذي كشف أن 99٪ من المديرين التنفيذيين في المناصب التقنية أكدوا أن مؤسساتهم ستزيد الإنفاق على الذكاء الاصطناعي في العام المقبل. كما هو الحال مع الثوراث التكنولوجية فإن الذكاء الاصطناعي وبشكل خاص الشبكات العصبية العميقة تثير الكثير من التساؤلات والشكوك مؤخرًا. خاصة مع الاتجاه المتزايد للاستفادة منها في الرعاية الصحية والعدالة الجنائية. الانتقاد الأكثر شيوعًا عند التعامل معها هو عدم قدرة البشر على فهم مايدور بين تلك الشبكات وآلية اتخاذ القرار ومقارنته بالقرار البشري.مما جعل البعض يرى أن التطور التقني مرحب به في الجانب النظري, وليس كذلك بالنسبة للجانب العملي والتطبيقي. 
 



## أنواع الخوارزميات السرية أو السوداء
اغلب الخوارزميات في االذكاء الاصطناعي إلى حد ما تعتبر مغلقة. تتمثل إحدى الأفكار الرئيسية للتعلم الآلي في أن النماذج تعتمد على البيانات  (Data-Driven Model). يقودنا هذا بشكل أساسي إلى مشاكل رئيسية مثل:   كيف يمكن أن نفسر هذه الخوارزميات،  كيف نتأكد من شفافيتها في صنع القرار ، إلى جانب التأكد من أن نتائج الخوارزمية المذكورة عادلة وصحيحة إحصائيًا.
مثل العديد من الأمور التي تتضمن الذكاء الاصطناعي ، هناك بعض اللبس حول مشكلة الخوارزميات الشبيهة بالصندوق الأسود. يعود جذر المشكلة لأكثر من سبب: منها تطور البرامج -خصوصًا المكتبات عالية المستوى (High-level and Abstract libraries)- والتي أصبحت جيدة بما يكفي لتغني عن معرفة ما يدور خلف العمليات الأساسية. مما جعل الصناديق السوداء (black boxes) السمة الأساسية للتعلم العميق وتعلم الآلة. بالإضافة إلى أن هناك وظائف معقدة للغاية لهذه الخوارزميات بحيث يتعذر على الخبراء في بعض الأحيان تفكيك قرارات الشبكة وتتبع عمليات اتخاذ القرار.

أصدرت شركة [مايكروسوفت](https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/) في فبراير ٢٠٢٠  أكبر شبكة عصبية عميقة موجودة (ربما ليس لفترة طويلة) ، Turing-NLG. تحتوي هذه الشبكة على 17 مليار معلمة. من الواضح أن تفسير شبكة عصبية تحتوي على 17 مليار معامل سيكون صعبًا للغاية. أيضًا هناك نوع من الخوارزميات الخاصة، حيث أن تفاصيل عمل الكثير من التقنيات المؤتمتة مملوكة بحد كبير للقطاع الخاص ويتم اعتبارها أسرارًا تجارية ولا يتم الافصاح عن تفاصيلها حتى بموجب أمر قضائي. تخفي الشركات تفاصيل أنظمة الذكاء الاصطناعي الخاصة بها لأسباب مختلفة ، مثل الملكية الفكرية أو منع الجهات السيئة من التلاعب بالنظام. في هذه الحالة ، قد يكون الأشخاص الذين أنشأوا نظام الذكاء الاصطناعي على دراية بمنطقه الداخلي ، لكن الأشخاص الذين يستخدمونه ليسوا كذلك. نحن نتعامل يوميًا مع بعض أنواع أنظمة الذكاء الاصطناعي الشبيهة بالصندوق الأسود ، بما في ذلك خوارزمية الترتيب في بحث Google ونظام توصية Amazon و Newsfeed على Facebook وغيرها. لكن الخطورة تكمن في الخوارزميات التي يتم استخدامها لتحديد أحكام السجن وتحديد درجات الائتمان واتخاذ قرارات العلاج في المستشفيات.


![Parameter counts of several recently released pretrained language models. ]({{site.baseurl}}/{{site.baseurl}}/https://www.microsoft.com/en-us/research/uploads/prod/2020/02/TurningNGL_Model__1400x788.png)




تم تسليط الضوء على الحاجة إلى الشفافية والتفسير في عمل الخوارزميات بعد حدوث العديد من القضايا. من أبرزها خوارزمية التعرف على الوجه من Google التي صنفت بعض من اصحاب البشرة السوداء على أنهم [غوريلا](https://www.forbes.com/sites/mzhang/2015/07/01/google-photos-tags-two-african-americans-as-gorillas-through-facial-recognition-software/?sh=1893955b713d). نظرًا لعدم قدرة Google على إصلاح الخوارزمية وإزالة التحيز الخوارزمي الذي أدى إلى هذه المشكلة ، فقد قامت بحل المشكلة عن طريق إزالة الكلمات المتعلقة بالقرود من محرك بحث صور Google. يوضح هذا طبيعة الصندوق الأسود المزعومة للعديد من خوارزميات التعلم الآلي. 
كان هناك العديد من النقاشات في المراجعات الأدبية حول عدالة وشفافية مثل هذه الخوارزميات المغلقة. والتي نشأت أساسًا من التحليل الذي أجرته مجموعة ProPublica مدعيا أن نموذج التنبؤ COMPAS – أداة لدعم القرار تستخدمها بعض المحاكم الأمريكية لتقييم احتمال عودة المدعى عليهم إلى الإجرام- متحيز عنصريًا . قامت هذه الأداء بحساب نتيجة تتنبأ باحتمالية ارتكابهم جريمة في المستقبل. تم تصنيف معتقل من أصل افريقي ليس لديه سجل إجرامي؛ بإنه خطر على المجتمع واحتمالية عودته للجريمة عالية. بينما تم تصنيف معتقل أبيض لديه سجل اجرامي حافل على أنه منخفض المخاطر واحتمالية عودته للجريمة ضئيلة!
  يمكن أن يؤدي هذا النوع من الأخطاء إلى سنوات من السجن الإضافي ، أو إطلاق سراح الأفراد الخطرين أو المتطرفين في المجتمع. يلفت هذا النوع من الدراسات الانتباه إلى مدى أهمية الشفافية في اتخاذ القرارات القضائية عند استخدام الذكاء الاصطناعي, التعلم الآلي أو الأنواع أخرى من النماذج الإحصائية. لا يمكننا تحديد ما إذا كانت هذه الاخطاء ناتجة عن أخطاء في الحساب أو أخطاء في إدخال البيانات أو أخطاء من مصدر آخر (أو حتى إذا كانت من الأساس تصنف ك أخطاء).
  
  إحدى المشكلات التي تنشأ من افتقارنا إلى قابلية شرح الخوارزميات هي أننا لا نعرف ما الذي تم تدريب النموذج عليه. وأفضل توضيح لهذا قصة يدور بعض الجدل حول حقيقتها ولكن الدروس التي يمكننا استخلاصها منها ذات قيمة. في الستينيات  من القرن الماضي وفقًا [لموروث الذكاء الاصطناعي](https://www.jefftk.com/p/detecting-tanks) كان الجيش الأمريكي مهتمًا بتطوير خوارزمية بغية كشف دبابات العدو المتخفية في الغابات. قام الباحثون بتدريب شبكة عصبية على 50 صورة لدبابات مموهة في الأشجار، و 50 صورة لأشجار بدون دبابات. قاموا بتدريب شبكة عصبية على التمييز بين فئتين من الصور; كانت النتائج مبهرة وتم تسليمها للبنتاغون. لاحقًا عندما تم اختبار الخوارزمية على صور إضافية ، كان أداؤها سيئًا للغاية. مما أربك الباحثين لأن النتائج كانت إيجابية أثناء مرحلة التطوير. بعد فترة لاحظ أحد الباحثين أنه في المجموعة الأصلية المكونة من 200 صورة ، تم التقاط جميع الصور مع الدبابات في يوم غائم بينما تم التقاط جميع الصور بدون دبابات في يوم مشمس. طُلب من الشبكة العصبية فصل مجموعتي الصور واختارت الطريقة الأكثر وضوحًا للقيام بذلك - ليس من خلال البحث عن دبابة مموهة مختبئة خلف شجرة ، ولكن بمجرد النظر إلى لون السماء. أصبح الجيش الآن يملك خوارزمية بملايين الدولارات يمكنها إخبارك ما إذا كان الجو مشمسًا أم لا!
 

في المقابل إهمال استخدام الخوارزميات القابلة للتفسير له نتائج سلبية خصوصًا في القضايا الحساسة والمتعلقة بالمصلحة العامة. هناك حجتين قام على اساساها العديد من المطالبات بإعطاء الأولوية للخوارزميات القابلة للتفسير بدلًا من الخوارزمية غير القابلة للتفسير: أولاً ، بغض النظر عن التعريف الفني للعدالة أو الشفافية، فمن الأسهل مناقشة عدالة الخوارزمية قابلة للتفسير بدلاً من مناقشة خوارزمية سرية. تزود الخوارزميات القابلة للتفسير المدعى عليهم والجمهور بمعلومات ضرورية حول الأدوات المستخدمة للسلامة والعدالة ، مما يسمح لجمهور أوسع بالمشاركة في مناقشة عدالتها. ثانيًا ، تشكل الشفافية نوعًا خاصًا من العدالة الإجرائية التي يجب أخذها في الاعتبار بجدية. الجدل القائم أساسه بأنه ليس من العدل أن يتم اتخاذ قرارات تغير الحياة بنظام عرضة للخطأ ، دون استحقاق تفسير واضح يمكن التحقق منه.

## الخوارزميات المفسرة (interpretability)  مقابل الخوارزميات القابلة للتفسير (Explainability)
 تستخدم بعض وسائل الإعلام التي تغطي أبحاث الذكاء الاصطناعي المصطلحين Explainability vs interpretability بالتبادل بالرغم من وجود اختلاف جوهري بينهما .الخوارزميات المفسرة (interpretability)  عبارة عن خوارزميات تقدم شرحًا واضحًا لعمليات اتخاذ القرار. بالإضافة لإمكانية ملاحظة السبب والنتيجة داخل النظام. بعبارة أخرى مدى قدرتك على التنبؤ بما سيحدث ، بالنظر إلى التغيير في المدخلات أو القيم الحسابية (Parameters). على سبيل المثال (decision trees and linear regression) يمكنك بوضوح تتبع المسار الذي تأخذه البيانات المدخلة عندما تمر عبر نموذج الذكاء الاصطناعي.

 بينما الخوارزميات القابلة للتفسير (Explainability) هو المدى الذي يمكن به شرح الميكانيكا الداخلية للآلة أو نظام التعلم العميق من منظور الإنسان. من السهل إغفال الاختلاف الدقيق مع الخوارزميات المفسرة ، لكن يمكن اعتبرها على هذا النحو: القابلية للتفسير تتعلق بالقدرة على تمييز الميكانيكا دون معرفة السبب بالضرورة. بينما المفسرة هي القدرة على شرح ما يحدث حرفيًا.
قد يكون هذا مربكًا بعض الشيء ، لكنه يمثل نقطة انطلاق جيدة للتفكير في كيفية ارتباط المفهومين ببعضهما البعض.

## الأساطير حول الخوازميات غير قابلة للتفسير

-	هناك اعتقاد شائع بأن النماذج الأكثر تعقيدًا هي أكثر دقة ، مما يعني أن النموذج غير القابل للتفسير ضروري لأداء تنبؤي أفضل. في الواقع هذا ليس صحيحًا في كثير من الأحيان ، لا سيما عندما تكون البيانات منظمة ((Structured ، مع تمثيل جيد للخصائص (Features). عند المقارنة بين اداء خوارزميات تعلم الآلة في التعامل مع المشاكل التي تمتلك بيانات منظمة مع خصائص ذات مغزى ، فغالبًا لا يوجد فرق كبير في الأداء بين الخوارزميات المعقدة مثل ((deep neural networks, boosted decision trees, random forests)) والخوارزميات البسيطة ((logistic regression, decision lists.  بشكل عام في الجانب التطبيقي لعلم البيانات، الاختلافات الصغيرة في الاداء بين خوازميات الذكاء الاصطناعي يمكن أن يتم التجاوز عنها بقدرة الخوارزمية على تفسير النتائج ومعالجة البيانات بشكل أفضل.

![الدقة مقابل التعقيد]({{site.baseurl}}/https://miro.medium.com/max/700/0*fvrBaILFAaCCsYHT)

-	هناك مفهوم خاطئ أكثر أهمية من مصطلح التفسير (Explanation ) و غالبًا ما يُستخدم بطريقة مضللة ، لأن النماذج المفسرة لا تحاول دائمًا محاكاة العمليات الحسابية للنموذج الأصلي. حتى النموذج المفسر الذي يعمل بشكل مماثل تقريبًا للخوارزمية المغلقة قد يستخدم خصائص (Features)  مختلفة تمامًا. عودة إلى الأداة المستخدمة في التنبؤ بالعودة إلى الجريمة ، حيث الهدف هو التنبؤ بما إذا كان سيتم القبض على شخص ما في غضون فترة زمنية معينة بعد إطلاق سراحه من السجن. تعتمد معظم خوارزميات التنبؤ بالعودة إلى الإجرام بشكل مباشر على خصائص مثل العمر والتاريخ الجنائي، بالمقابل لا تعتمد بشكل مباشر على العرق. لكن هناك ارتباط وثيق بين هذه الخصائص والعرق في قواعد البيانات المحفوظة. بالتالي فإن النموذج المفسر من هذه الخوارزمية قد يستخلص قاعدة مفادها ( سيتم القبض على هذا الشخص لأنه ينتمي للعرق الأفريقي). قد يكون نموذج التفسير  دقيق حيث يحاكي بشكل صحيح تنبؤات النموذج الأصلي ، لكنه لن يكون وفيا أو يعمل وفقًا للمبادئ التي قام عليها النموذج الأصلي.


إذا تعلمنا شيء من القصص السابقة ، فإنه على الرغم من إمكانية استخدام التكنولوجيا بشكل مشكوك فيه ، إلا أن هناك العديد من الطرق التي يمكن أن تنتج بها نتائج سلبية. من البديهي أن مستوى الضرر يعتمد على مجال التطبيق فالخوارزمية السيئة التي توصي بالموسيقى أو المطاعم ستسبب ضررًا أقل من الخوارزمية التي تساعد في تشخيص السرطان أو التوصية بالإفراج عن السجناء. 
ونظرًا لأن مجالات مثل الرعاية الصحية تتطلع إلى زيادة الاعتماد على الذكاء الاصطناعي وأنظمة التعلم العميق ، حيث ستكون أسئلة المساءلة والشفافية مهمة بشكل خاص. إن لم نتمكن من تقديم تفسير بشكل صحيح سيحد ذلك من الاستخدام المحتمل لهذه التقنيات. ختامًا بصرف النظر عن الاعتبارات القانونية والمهنية التي يجب إتخاذها، هناك أيضًا حجة مفادها أن تحسين القابلية للتفسير وإمكانية التفسير مهم حتى في سيناريوهات الأعمال الأكثر شيوعًا. يمكن أن يساعد فهم كيفية عمل الخوارزمية فعليًا في مواءمة أنشطة علماء البيانات والمحللين بشكل أفضل مع الأسئلة والاحتياجات الأساسية لمنظمتهم.


## المراجع
1. Turing-NLG: A 17-billion-parameter language model by Microsoft. Microsoft Research. (2020, February 13). https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/. 
2. Zhang, M. (2015, July 1). Google Photos Tags Two African-Americans As Gorillas Through Facial Recognition Software. Forbes. https://www.forbes.com/sites/mzhang/2015/07/01/google-photos-tags-two-african-americans-as-gorillas-through-facial-recognition-software/?sh=1893955b713d. 
3. Team, I. (2018, October 16). Forbes Insights: On Your Marks: Business Leaders Prepare For Arms Race In Artificial Intelligence. Forbes. https://www.forbes.com/sites/insights-intelai/2018/07/17/on-your-marks-business-leaders-prepare-for-arms-race-in-artificial-intelligence/?sh=1224b4181946. 
4.Detecting Tanks. (n.d.). https://www.jefftk.com/p/detecting-tanks. 
5.
6.
7.
